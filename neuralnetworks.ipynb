{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The materials in this notebook are sourced from [PyTorch's 60 Minute Blitz](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py) with annotations from their [docs](https://pytorch.org/docs/stable/).\n",
    "\n",
    "We will construct a network that classifies digit images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://pytorch.org/tutorials/_images/mnist.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a simple feed-forward network. It takes the input, feeds it through several layers one after the other, and then finally gives the output.\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "* Define the neural network that has some learnable parameters (or weights)\n",
    "* Iterate over a dataset of inputs\n",
    "* Process input through the network\n",
    "* Compute the loss (how far is the output from being correct)\n",
    "* Propagate gradients back into the networkâ€™s parameters\n",
    "* Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a91126678942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        First convolution layer\n",
    "          1 input image channel\n",
    "          6 output channels\n",
    "          5x5 square convolution kernel\n",
    "        Second convolution layer\n",
    "          6 input image channel\n",
    "          16 output channels\n",
    "          5x5 square convolution kernel\n",
    "          \n",
    "        First fully connected layer\n",
    "          1 input image channel\n",
    "          6 output channels\n",
    "          5x5 square convolution kernel\n",
    "        Second fully connected layer\n",
    "          1 input image channel\n",
    "          6 output channels\n",
    "          5x5 square convolution kernel\n",
    "        Third fully connected layer\n",
    "          1 input image channel\n",
    "          6 output channels\n",
    "          5x5 square convolution kernel\n",
    "        \"\"\" \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.Conv2d\n",
    "\n",
    "Applies a 2D **convolution** over an input signal composed of several input planes.\n",
    "\n",
    ">Slides an nxn kernel across the input matrix performing mathematical convolution on the submatrix that the kernel covers. The values or weights of the kernel matrix are learned by backpropogation.\n",
    "\n",
    "In the simplest case, the output value of the layer with input size $(N, C_{in}, H, W)$ and output $(N, C_{out}, H_{out}, W_{out})$ can be precisely described as:\n",
    "$$out(N_i, C_{out_j}) = bias(C_{out_j} + \\sum_{k=0}^{C_{in}-1}weight(C_{out_j},k)*input(N_i,k)$$\n",
    "where $*$ is the valid 2D cross-correlation operator, $N$ is a batch size, $C$ denotes a number of channels, $H$ is a height of input planes in pixels, and $W$ is width in pixels.\n",
    "\n",
    "### torch.nn.Linear\n",
    "\n",
    "Applies a linear transformation to the incoming data: $y = xA^T + b$ \n",
    "\n",
    "### torch.nn.functional.max_pool2d\n",
    "\n",
    "Applies a 2D **max pooling** over an input signal composed of several input planes.\n",
    "\n",
    ">Max pooling reduces the dimensionality of an input by applying a max filter to usually non-overlapping subregions of the initial representation. Pooling layers are commonly inserted between successive convolution layers to reduce the amount of parameters and computation in the network, and to help control over fitting.\n",
    "\n",
    "In the simplest case, the output value of the layer with input size $(N, C, H, W), output $(N, C, H_{out}, W_{out}) and `kernel_size` $(kH, kW)$ can be precisely described as:\n",
    "\n",
    "$$out(N_i, C_j, H, W) = \\max\\limits_{m=0, \\dots, kH-1} \\max\\limits_{n=0, \\dots, kW-1} input(N_i, C_j, stride[0] * h + m, stride[1] * w + n)$$\n",
    "\n",
    "### torch.nn.functional.relu\n",
    "\n",
    "Applies the rectified linear unit function element-wise $ReLU(x) = max(0,x)$\n",
    "\n",
    "<img src=\"https://pytorch.org/docs/stable/_images/ReLU.png\" width=400/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By defining the `forward` function, the `backward` function is automatically defined by `autograd`. The `forward` functio can unclude any Tensor operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learnable parameters of a model are returned by `net.parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())   # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try a random 32x32 input Note: Expected input size to this net(LeNet) is 32x32. To use this net on MNIST dataset, please resize the images from the dataset to 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0136,  0.0495,  0.0561,  0.0133, -0.1004,  0.0282,  0.0582, -0.0402,\n",
      "         -0.0497,  0.0237]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample. For example, `nn.Conv2d` will take in a 4D Tensor of nSamples x nChannels x Height x Width. If you have a single sample, just use `input.unsqueeze(0)` to add a fake batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap:**\n",
    "\n",
    "* `torch.Tensor` - A *multi-dimensional array* with support for autograd operations like `backward()`.\n",
    "* `nn.Module` - Neural network module. *Convenient way of encapsulating parameters*, with helpers for moving them to GPU, exporting, loading, etc.\n",
    "* `nn.Parameter` - A kind of Tensor, that is *automatically registered as a parameter when assigned as an attribute to a `Module`.\n",
    "* `autograd.Function` - Implements *forward and backward definitions of an autograd operation.* Every `Tensor` operation, creates at last a single `Function` node, that connects to functions that created a `Tensor` and *encodes its history.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target.\n",
    "\n",
    "There are several different loss functions under the nn package. A simple loss is: `nn.MSELoss` which computes the mean-squared error between the input and the target.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2344, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)    # dummy target\n",
    "target = target.view(1, -1) # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.MSELoss\n",
    "\n",
    "Creates a criterion that measures the mean squared error between $n$ elements in the input $x$ and target $y$.\n",
    "\n",
    "The loss can be described as:\n",
    "$$l(x,y) = L = \\{l_1, \\dots, l_N\\}^\\top, l_n = (x_n - y_n)^2$$\n",
    "Where N is the batch size. If reduce is `True`, then:\n",
    "$$l(x,y) = \\begin{cases} mean(L), & \\mbox{if } size\\_average\\mbox{ = True,} \\\\sum(L), & \\mbox{if } size\\_average\\mbox{ = False} \\end{cases}$$\n",
    "The sum operation still operates over all the elements, and divides by $n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MseLossBackward at 0x7f7334b5cf98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
