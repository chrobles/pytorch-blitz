{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The materials in this notebook are sourced from [PyTorch's 60 Minute Blitz](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py) with annotations from their [docs](https://pytorch.org/docs/stable/).\n",
    "\n",
    "We will construct a network that classifies digit images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://pytorch.org/tutorials/_images/mnist.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a simple feed-forward network. It takes the input, feeds it through several layers one after the other, and then finally gives the output.\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "* Define the neural network that has some learnable parameters (or weights)\n",
    "* Iterate over a dataset of inputs\n",
    "* Process input through the network\n",
    "* Compute the loss (how far is the output from being correct)\n",
    "* Propagate gradients back into the networkâ€™s parameters\n",
    "* Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a91126678942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        First convolution layer\n",
    "          1 input image channel\n",
    "          6 output channels\n",
    "          5x5 square convolution kernel\n",
    "        Second convolution layer\n",
    "          6 input image channel\n",
    "          16 output channels\n",
    "          5x5 square convolution kernel\n",
    "          \n",
    "        First fully connected layer\n",
    "          1 input image channel\n",
    "          6 output channels\n",
    "          5x5 square convolution kernel\n",
    "        Second fully connected layer\n",
    "          1 input image channel\n",
    "          6 output channels\n",
    "          5x5 square convolution kernel\n",
    "        Third fully connected layer\n",
    "          1 input image channel\n",
    "          6 output channels\n",
    "          5x5 square convolution kernel\n",
    "        \"\"\" \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.Conv2d\n",
    "\n",
    "Applies a 2D **convolution** over an input signal composed of several input planes.\n",
    "\n",
    ">Slides an nxn kernel across the input matrix performing mathematical convolution on the submatrix that the kernel covers. The values or weights of the kernel matrix are learned by backpropogation.\n",
    "\n",
    "In the simplest case, the output value of the layer with input size $(N, C_{in}, H, W)$ and output $(N, C_{out}, H_{out}, W_{out})$ can be precisely described as:\n",
    "$$out(N_i, C_{out_j}) = bias(C_{out_j} + \\sum_{k=0}^{C_{in}-1}weight(C_{out_j},k)*input(N_i,k)$$\n",
    "where $*$ is the valid 2D cross-correlation operator, $N$ is a batch size, $C$ denotes a number of channels, $H$ is a height of input planes in pixels, and $W$ is width in pixels.\n",
    "\n",
    "### torch.nn.Linear\n",
    "\n",
    "Applies a linear transformation to the incoming data: $y = xA^T + b$ \n",
    "\n",
    "### torch.nn.funtional.max_pool2d\n",
    "\n",
    "Applies a 2D **max pooling** over an input signal composed of several input planes.\n",
    "\n",
    ">Max pooling reduces the dimensionality of an input by applying a max filter to usually non-overlapping subregions of the initial representation. Pooling layers are commonly inserted between successive convolution layers to reduce the amount of parameters and computation in the network, and to help control over fitting.\n",
    "\n",
    "In the simplest case, the output value of the layer with input size $(N, C, H, W), output $(N, C, H_{out}, W_{out}) and `kernel_size` $(kH, kW)$ can be precisely described as:\n",
    "\n",
    "$$out(N_i, C_j, H, W) = \\max\\limits_{m=0, \\dots, kH-1} \\max\\limits_{n=0, \\dots, kW-1} input(N_i, C_j, stride[0] * h + m, stride[1] * w + n)$$\n",
    "\n",
    "### torch.nn.funtional.relu\n",
    "\n",
    "Applies the rectified linear unit function element-wise $ReLU(x) = max(0,x)$\n",
    "\n",
    "<img src=\"https://pytorch.org/docs/stable/_images/ReLU.png\" width=400/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
